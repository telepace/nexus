#!/usr/bin/env python3
"""
æµ‹è¯•ä¸­æ–‡å†…å®¹åœ¨ ContentChunk ä¸­çš„å­˜å‚¨å’Œè¯»å–
"""
import uuid
from sqlmodel import Session, select, text
from app.core.db import engine
from app.models.content import ContentChunk, ContentItem
from app.utils.content_chunker import ContentChunker

def test_chinese_encoding():
    """æµ‹è¯•ä¸­æ–‡ç¼–ç é—®é¢˜"""
    
    # æµ‹è¯•ç”¨çš„ä¸­æ–‡å†…å®¹
    chinese_content = """
# ä¸­æ–‡æµ‹è¯•æ ‡é¢˜

è¿™æ˜¯ä¸€æ®µä¸­æ–‡æµ‹è¯•å†…å®¹ï¼ŒåŒ…å«å„ç§ä¸­æ–‡å­—ç¬¦ï¼š

## æŠ€æœ¯æ–‡æ¡£
- äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•
- æœºå™¨å­¦ä¹ ç®—æ³•ä¼˜åŒ–
- æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒ

è¿™é‡Œæœ‰ä¸€äº›ç‰¹æ®Šå­—ç¬¦ï¼š"ä½ å¥½ä¸–ç•Œ"ï¼Œæµ‹è¯•ç¼–ç æ˜¯å¦æ­£ç¡®ã€‚

```python
# ä»£ç å—ä¸­çš„ä¸­æ–‡æ³¨é‡Š
def hello_world():
    print("ä½ å¥½ï¼Œä¸–ç•Œï¼")  # æ‰“å°ä¸­æ–‡
    return "æˆåŠŸ"
```

## æ•°æ®ç»Ÿè®¡
| é¡¹ç›® | æ•°é‡ | è¯´æ˜ |
|------|------|------|
| ç”¨æˆ·æ•° | 1000 | æ´»è·ƒç”¨æˆ· |
| æ–‡æ¡£æ•° | 500 | æŠ€æœ¯æ–‡æ¡£ |

æµ‹è¯•å®Œæˆã€‚
"""
    
    print("ğŸ” å¼€å§‹æµ‹è¯•ä¸­æ–‡ç¼–ç ...")
    print(f"åŸå§‹å†…å®¹é•¿åº¦: {len(chinese_content)} å­—ç¬¦")
    print(f"åŸå§‹å†…å®¹(å‰100å­—ç¬¦): {chinese_content[:100]}...")
    
    try:
        with Session(engine) as session:
            # 1. é¦–å…ˆæ£€æŸ¥æ•°æ®åº“è¿æ¥çš„ç¼–ç è®¾ç½®
            print("\nğŸ“Š æ£€æŸ¥æ•°æ®åº“ç¼–ç è®¾ç½®...")
            result = session.exec(select(1)).first()
            print(f"æ•°æ®åº“è¿æ¥æ­£å¸¸: {result}")
            
            # æ£€æŸ¥æ•°æ®åº“ç¼–ç 
            encoding_result = session.exec(
                text("SELECT name, setting FROM pg_settings WHERE name LIKE '%encoding%' OR name LIKE '%locale%'")
            ).all()
            
            print("æ•°æ®åº“ç¼–ç è®¾ç½®:")
            for row in encoding_result:
                print(f"  {row[0]}: {row[1]}")
            
            # 2. åˆ›å»ºä¸€ä¸ªæµ‹è¯•ç”¨çš„ ContentItem (å¦‚æœä¸å­˜åœ¨)
            test_user_id = uuid.uuid4()
            test_content_item = ContentItem(
                id=uuid.uuid4(),
                user_id=test_user_id,
                type="text",
                title="ä¸­æ–‡ç¼–ç æµ‹è¯•",
                processing_status="completed"
            )
            session.add(test_content_item)
            session.commit()
            
            # 3. ä½¿ç”¨ ContentChunker åˆ†å—ä¸­æ–‡å†…å®¹
            print("\nğŸ”„ ä½¿ç”¨ ContentChunker åˆ†å—ä¸­æ–‡å†…å®¹...")
            chunker = ContentChunker(max_chunk_size=500)
            content_chunks = chunker.create_content_chunks(
                test_content_item.id, 
                chinese_content
            )
            
            print(f"ç”Ÿæˆäº† {len(content_chunks)} ä¸ªå†…å®¹åˆ†å—")
            
            # æ£€æŸ¥å†…å­˜ä¸­çš„åˆ†å—å†…å®¹
            print("\nğŸ§  æ£€æŸ¥å†…å­˜ä¸­çš„åˆ†å—å†…å®¹...")
            for i, chunk in enumerate(content_chunks):
                chunk_content = chunk.chunk_content
                has_chinese = any('\u4e00' <= char <= '\u9fff' for char in chunk_content)
                print(f"åˆ†å— {i+1}: æœ‰ä¸­æ–‡={has_chinese}, å†…å®¹é•¿åº¦={len(chunk_content)}")
                print(f"  å†…å®¹: {chunk_content[:50]}...")
            
            # 4. ä¿å­˜åˆ°æ•°æ®åº“
            print("\nğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
            for chunk in content_chunks:
                session.add(chunk)
            session.commit()
            
            print("âœ… å†…å®¹åˆ†å—ä¿å­˜æˆåŠŸ")
            
            # 5. ä»æ•°æ®åº“è¯»å–å¹¶éªŒè¯
            print("\nğŸ“– ä»æ•°æ®åº“è¯»å–å¹¶éªŒè¯...")
            saved_chunks = session.exec(
                select(ContentChunk)
                .where(ContentChunk.content_item_id == test_content_item.id)
                .order_by(ContentChunk.chunk_index)
            ).all()
            
            print(f"ä»æ•°æ®åº“è¯»å–åˆ° {len(saved_chunks)} ä¸ªåˆ†å—")
            
            # 6. éªŒè¯æ¯ä¸ªåˆ†å—çš„å†…å®¹
            original_chunks = []
            for chunk in content_chunks:
                original_chunks.append(chunk.chunk_content)
            
            for i, chunk in enumerate(saved_chunks):
                print(f"\n--- åˆ†å— {i+1} ({chunk.chunk_type}) ---")
                print(f"å­—ç¬¦æ•°: {chunk.char_count}")
                print(f"è¯æ•°: {chunk.word_count}")
                
                stored_content = chunk.chunk_content
                original_content = original_chunks[i] if i < len(original_chunks) else ""
                
                print(f"åŸå§‹å†…å®¹: {original_content[:50]}...")
                print(f"å­˜å‚¨å†…å®¹: {stored_content[:50]}...")
                
                # æ¯”è¾ƒå†…å®¹æ˜¯å¦ä¸€è‡´
                if stored_content == original_content:
                    print("âœ… å†…å®¹å®Œå…¨ä¸€è‡´ï¼Œç¼–ç æ­£å¸¸")
                else:
                    print("âŒ å†…å®¹ä¸ä¸€è‡´ï¼Œå¯èƒ½å­˜åœ¨ç¼–ç é—®é¢˜")
                    print(f"åŸå§‹é•¿åº¦: {len(original_content)}, å­˜å‚¨é•¿åº¦: {len(stored_content)}")
                    
                    # é€å­—ç¬¦æ¯”è¾ƒï¼Œæ‰¾å‡ºå·®å¼‚
                    for j, (orig_char, stored_char) in enumerate(zip(original_content, stored_content)):
                        if orig_char != stored_char:
                            print(f"  å·®å¼‚ä½ç½® {j}: åŸå§‹='{orig_char}' (U+{ord(orig_char):04X}), å­˜å‚¨='{stored_char}' (U+{ord(stored_char):04X})")
                            if j >= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªå·®å¼‚
                                break
            
            # 7. æ¸…ç†æµ‹è¯•æ•°æ®
            print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®...")
            for chunk in saved_chunks:
                session.delete(chunk)
            session.delete(test_content_item)
            session.commit()
            print("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == "__main__":
    test_chinese_encoding()
    print("\nğŸ‰ ä¸­æ–‡ç¼–ç æµ‹è¯•å®Œæˆï¼") 