#!/usr/bin/env python3
"""
Create test content data script.

This script creates test content items with different types (PDF, URL, text)
for testing the content library and reader functionality.
"""

import logging
import sys
import uuid
from pathlib import Path

# Add the backend directory to Python path
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

# Local imports after path modification
from sqlmodel import Session, select  # noqa: E402

from app.core.db import engine  # noqa: E402
from app.models.content import ContentItem  # noqa: E402
from app.models import User  # noqa: E402

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main() -> None:
    """Create test content data."""
    logger.info("🌱 开始创建测试内容数据...")

    try:
        with Session(engine) as session:
            # Get the admin user
            admin_user = session.exec(
                select(User).where(User.email == "admin@telepace.cc")
            ).first()
            
            if not admin_user:
                logger.error("❌ 未找到管理员用户，请先运行 make backend-init-data")
                sys.exit(1)

            # Test content data
            test_contents = [
                {
                    "type": "pdf",
                    "source_uri": "https://arxiv.org/pdf/2301.00234.pdf",
                    "title": "Attention Is All You Need - Transformer架构详解",
                    "summary": "这是一篇关于Transformer架构的经典论文，详细介绍了注意力机制的工作原理和应用。",
                    "content_text": """# Attention Is All You Need

## 摘要
我们提出了一种新的简单网络架构——Transformer，它完全基于注意力机制，完全摒弃了循环和卷积。在两个机器翻译任务上的实验表明，这些模型在质量上更优越，同时更易于并行化，训练时间显著减少。

## 1. 引言
循环神经网络，特别是长短期记忆网络（LSTM）和门控循环单元（GRU），已经被确立为序列建模和转换问题（如语言建模和机器翻译）的最先进方法。

## 2. 背景
减少顺序计算的目标也构成了扩展神经GPU、ByteNet和ConvS2S的基础，它们都使用卷积神经网络作为基本构建块，并行计算所有输入和输出位置的隐藏表示。

## 3. 模型架构
大多数竞争性神经序列转换模型都具有编码器-解码器结构。在这里，编码器将符号表示的输入序列映射到连续表示的序列。给定z，解码器然后一次生成一个元素的输出序列。

### 3.1 编码器和解码器堆栈
**编码器：** 编码器由N=6个相同层的堆栈组成。每层有两个子层。第一个是多头自注意力机制，第二个是简单的位置全连接前馈网络。

**解码器：** 解码器也由N=6个相同层的堆栈组成。除了每个编码器层中的两个子层之外，解码器还插入第三个子层，该子层对编码器堆栈的输出执行多头注意力。

### 3.2 注意力
注意力函数可以描述为将查询和一组键值对映射到输出，其中查询、键、值和输出都是向量。输出计算为值的加权和，其中分配给每个值的权重由查询与相应键的兼容性函数计算。

#### 3.2.1 缩放点积注意力
我们称我们的特定注意力为"缩放点积注意力"。输入包括维度dk的查询和键，以及维度dv的值。我们计算查询与所有键的点积，将每个除以√dk，并应用softmax函数来获得值的权重。

#### 3.2.2 多头注意力
我们发现，与其使用dmodel维度的键、值和查询执行单个注意力函数，不如将查询、键和值线性投影h次到dk、dk和dv维度是有益的。

## 4. 为什么选择自注意力
在本节中，我们将自注意力层的各个方面与循环层和卷积层进行比较，这些层通常用于将一个可变长度的符号表示序列映射到另一个等长序列。

## 5. 训练
本节描述了我们模型的训练制度。

### 5.1 训练数据和批处理
我们在标准的WMT 2014英德数据集上进行训练，该数据集包含大约450万个句子对。

### 5.2 硬件和调度
我们在一台配备8个NVIDIA P100 GPU的机器上训练我们的模型。

## 6. 结果
在本节中，我们展示了Transformer在机器翻译、英语选区解析和其他任务上的结果。

### 6.1 机器翻译
在WMT 2014英德翻译任务上，大型Transformer模型（表2中的Transformer（big））的性能优于之前报告的最佳模型（包括集成模型）超过2.0 BLEU，建立了新的最先进的BLEU分数28.4。

## 7. 结论
在这项工作中，我们提出了Transformer，这是第一个完全基于注意力的序列转换模型，用多头自注意力取代了编码器-解码器架构中最常用的循环层。""",
                    "processing_status": "completed",
                },
                {
                    "type": "url",
                    "source_uri": "https://zh.wikipedia.org/wiki/人工智能",
                    "title": "人工智能 - 维基百科",
                    "summary": "人工智能（AI）是由机器展现的智能，与人类和动物展现的自然智能形成对比。",
                    "content_text": """# 人工智能

人工智能（英语：Artificial Intelligence，缩写为AI）亦称机器智能，指由人制造出来的机器所表现出来的智能。通常人工智能是指通过普通计算机程序来呈现人类智能的技术。

## 定义
人工智能的定义可以分为两部分，即"人工"和"智能"。"人工"比较好理解，争议性也不大。有时我们会要考虑什么是人力所能及制造的，或者人自身的智能程度有没有高到可以创造人工智能的地步，等等。但总的来说，"人工系统"就是通常意义下的人工系统。

## 历史
人工智能的概念最早可以追溯到古代神话和哲学思想。然而，现代人工智能的发展始于20世纪中叶。

### 早期发展（1940-1960年代）
- 1943年：沃伦·麦卡洛克和沃尔特·皮茨发表了第一篇关于人工神经网络的论文
- 1950年：艾伦·图灵发表了著名的论文《计算机器与智能》，提出了图灵测试
- 1956年：达特茅斯会议，约翰·麦卡锡首次提出"人工智能"这一术语

### 第一次AI冬天（1970年代）
由于早期过于乐观的预期与实际进展的差距，AI研究遭遇了第一次低潮期。

### 专家系统时代（1980年代）
专家系统的兴起带来了AI的第二次繁荣，但随后又遭遇了第二次AI冬天。

### 机器学习复兴（1990年代至今）
随着计算能力的提升和大数据的出现，机器学习，特别是深度学习，推动了AI的快速发展。

## 主要技术领域

### 机器学习
机器学习是人工智能的一个分支，它使计算机能够在没有明确编程的情况下学习。

#### 监督学习
使用标记的训练数据来学习从输入到输出的映射函数。

#### 无监督学习
从未标记的数据中发现隐藏的模式或结构。

#### 强化学习
通过与环境的交互来学习最优行为策略。

### 深度学习
深度学习是机器学习的一个子集，使用多层神经网络来模拟人脑的工作方式。

### 自然语言处理
使计算机能够理解、解释和生成人类语言的技术。

### 计算机视觉
使计算机能够从图像或视频中获取有意义信息的技术。

### 机器人学
设计、构造、操作和使用机器人的技术。

## 应用领域

### 医疗健康
- 医学影像诊断
- 药物发现
- 个性化治疗
- 健康监测

### 交通运输
- 自动驾驶汽车
- 交通流量优化
- 智能交通系统

### 金融服务
- 算法交易
- 风险评估
- 欺诈检测
- 客户服务

### 教育
- 个性化学习
- 智能辅导系统
- 自动评分

### 娱乐
- 游戏AI
- 内容推荐
- 虚拟现实

## 伦理和社会影响

### 就业影响
AI的发展可能会导致某些工作岗位的消失，但也会创造新的就业机会。

### 隐私和安全
AI系统的广泛应用引发了对个人隐私和数据安全的担忧。

### 算法偏见
AI系统可能会延续或放大现有的社会偏见。

### 自主武器
AI在军事领域的应用引发了关于自主武器系统的伦理争议。

## 未来展望
人工智能的未来发展方向包括：
- 通用人工智能（AGI）的实现
- 更好的人机交互
- AI的可解释性和透明度
- 更加安全和可靠的AI系统
- AI与其他技术的融合

## 结论
人工智能正在快速发展，并在各个领域产生深远影响。虽然面临诸多挑战，但AI技术的进步为人类社会带来了巨大的机遇和潜力。""",
                    "processing_status": "completed",
                },
                {
                    "type": "text",
                    "source_uri": None,
                    "title": "深度学习基础概念",
                    "summary": "深度学习是机器学习的一个分支，使用多层神经网络来学习数据的复杂模式。",
                    "content_text": """# 深度学习基础概念

深度学习是机器学习的一个子领域，它使用具有多个隐藏层的神经网络来学习数据的复杂表示。这种方法受到人脑神经网络结构的启发，能够自动学习数据的层次化特征表示。

## 1. 神经网络基础

### 1.1 人工神经元
人工神经元是神经网络的基本单元，它模拟生物神经元的工作原理：
- 接收多个输入信号
- 对输入进行加权求和
- 通过激活函数产生输出

### 1.2 多层感知机
多层感知机（MLP）是最简单的深度神经网络：
- 输入层：接收原始数据
- 隐藏层：进行特征变换（可以有多层）
- 输出层：产生最终预测结果

## 2. 激活函数

激活函数为神经网络引入非线性，使其能够学习复杂的模式：

### 2.1 常用激活函数
- **ReLU（修正线性单元）**：f(x) = max(0, x)
  - 优点：计算简单，缓解梯度消失问题
  - 缺点：可能导致神经元死亡

- **Sigmoid**：f(x) = 1/(1 + e^(-x))
  - 优点：输出范围在(0,1)，适合概率输出
  - 缺点：容易饱和，梯度消失

- **Tanh**：f(x) = (e^x - e^(-x))/(e^x + e^(-x))
  - 优点：输出范围在(-1,1)，零中心化
  - 缺点：仍然存在梯度消失问题

## 3. 反向传播算法

反向传播是训练神经网络的核心算法：

### 3.1 前向传播
1. 输入数据通过网络层层传递
2. 每层计算加权和并应用激活函数
3. 最终得到网络输出

### 3.2 损失计算
使用损失函数衡量预测值与真实值的差异：
- 回归问题：均方误差（MSE）
- 分类问题：交叉熵损失

### 3.3 反向传播
1. 计算输出层的梯度
2. 逐层向前传播梯度
3. 使用链式法则计算每个参数的梯度

### 3.4 参数更新
使用梯度下降算法更新网络参数：
- 随机梯度下降（SGD）
- Adam优化器
- RMSprop等

## 4. 深度学习架构

### 4.1 卷积神经网络（CNN）
专门用于处理图像数据：
- **卷积层**：提取局部特征
- **池化层**：降低维度，增强鲁棒性
- **全连接层**：进行最终分类

### 4.2 循环神经网络（RNN）
用于处理序列数据：
- **LSTM**：长短期记忆网络，解决长期依赖问题
- **GRU**：门控循环单元，简化的LSTM
- **双向RNN**：同时考虑前向和后向信息

### 4.3 Transformer
基于注意力机制的架构：
- **自注意力机制**：捕获序列内部的依赖关系
- **多头注意力**：并行处理不同类型的信息
- **位置编码**：为序列添加位置信息

## 5. 训练技巧

### 5.1 正则化技术
防止过拟合：
- **Dropout**：随机丢弃部分神经元
- **L1/L2正则化**：在损失函数中添加惩罚项
- **批量归一化**：标准化每层的输入

### 5.2 学习率调度
- **学习率衰减**：训练过程中逐渐降低学习率
- **余弦退火**：周期性调整学习率
- **预热策略**：开始时使用较小的学习率

### 5.3 数据增强
增加训练数据的多样性：
- 图像：旋转、翻转、缩放、裁剪
- 文本：同义词替换、回译
- 音频：时间拉伸、噪声添加

## 6. 深度学习的优势与挑战

### 6.1 优势
- **自动特征学习**：无需手工设计特征
- **强大的表示能力**：能够学习复杂的非线性映射
- **端到端训练**：整个系统可以联合优化
- **泛化能力强**：在大数据上表现优异

### 6.2 挑战
- **数据需求大**：通常需要大量标注数据
- **计算资源密集**：训练需要强大的硬件支持
- **黑盒性质**：模型决策过程难以解释
- **过拟合风险**：在小数据集上容易过拟合

## 7. 应用领域

### 7.1 计算机视觉
- 图像分类
- 目标检测
- 语义分割
- 人脸识别

### 7.2 自然语言处理
- 机器翻译
- 情感分析
- 问答系统
- 文本生成

### 7.3 语音处理
- 语音识别
- 语音合成
- 说话人识别

### 7.4 推荐系统
- 协同过滤
- 内容推荐
- 序列推荐

## 8. 未来发展方向

### 8.1 模型架构创新
- 更高效的注意力机制
- 神经架构搜索（NAS）
- 可微分编程

### 8.2 训练方法改进
- 自监督学习
- 元学习
- 联邦学习

### 8.3 应用拓展
- 科学计算
- 药物发现
- 气候建模
- 自动驾驶

## 结论

深度学习作为人工智能的重要分支，已经在众多领域取得了突破性进展。随着算法的不断改进、计算能力的提升和数据的积累，深度学习将继续推动人工智能技术的发展，为人类社会带来更多的创新和变革。

理解深度学习的基础概念对于从事相关研究和应用开发至关重要。通过掌握神经网络、激活函数、反向传播等核心概念，我们可以更好地设计和优化深度学习模型，解决实际问题。""",
                    "processing_status": "completed",
                },
            ]

            # Create test content items
            for content_data in test_contents:
                # Check if content already exists
                existing_content = session.exec(
                    select(ContentItem).where(ContentItem.title == content_data["title"])
                ).first()
                
                if not existing_content:
                    content_item = ContentItem(
                        user_id=admin_user.id,
                        **content_data
                    )
                    session.add(content_item)
                    logger.info(f"创建测试内容: {content_data['title']}")
                else:
                    logger.info(f"测试内容已存在: {content_data['title']}")

            session.commit()

        logger.info("✅ 测试内容数据创建完成！")
        logger.info("")
        logger.info("📋 创建的测试内容包括:")
        logger.info("📄 PDF类型: Transformer架构详解")
        logger.info("🌐 URL类型: 人工智能维基百科")
        logger.info("📝 文本类型: 深度学习基础概念")

    except Exception as e:
        logger.error(f"❌ 创建测试内容失败: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 